{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wget\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import os,shutil\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "from skimage.transform import resize\n",
    "from IPython.display import clear_output\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mydir = r'C:\\\\Users\\\\炸酱面\\\\Downloads\\\\project\\\\warwick_qu_dataset_released_2016_07_08\\\\Warwick QU Dataset (Released 2016_07_08)'\n",
    "pathDir =  os.listdir(mydir)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset to 3 class : testA, test B, train and its masks.\n",
    "testsetA = []\n",
    "testsetB = []\n",
    "trainset = []\n",
    "testmaskA = []\n",
    "testmaskB = []\n",
    "trainmask = []\n",
    "\n",
    "for allDir in pathDir:      \n",
    "    if allDir.startswith('testA')==True and allDir.endswith('anno.bmp')==True:     \n",
    "\n",
    "        testmaskA.append(allDir)\n",
    "        \n",
    "    if allDir.startswith('testA')==True and allDir.endswith('anno.bmp')==False:\n",
    "  \n",
    "        testsetA.append(allDir)\n",
    "\n",
    "    if allDir.startswith('testB')==True and allDir.endswith('anno.bmp')==True:\n",
    "       \n",
    "        testmaskB.append(allDir)\n",
    "\n",
    "    if allDir.startswith('testB')==True and allDir.endswith('anno.bmp')==False:\n",
    "\n",
    "        testsetB.append(allDir)\n",
    "\n",
    "    if allDir.startswith('train')==True and allDir.endswith('anno.bmp')==True:\n",
    "        \n",
    "        trainmask.append(allDir)\n",
    "\n",
    "    if allDir.startswith('train')==True and allDir.endswith('anno.bmp')==False:\n",
    "        \n",
    "        trainset.append(allDir)\n",
    "\n",
    "#Build new dataset root  \n",
    "newdir = os.getcwd()\n",
    "raw_img_train_location = newdir+os.sep+'train'+os.sep+'raw'\n",
    "raw_img_testA_location = newdir+os.sep+'testA'+os.sep+'raw'\n",
    "raw_img_testB_location = newdir+os.sep+'testB'+os.sep+'raw'\n",
    "anno_img_train_location = newdir+os.sep+'train'+os.sep+'anno'\n",
    "anno_img_testA_location = newdir+os.sep+'testA'+os.sep+'anno'\n",
    "anno_img_testB_location = newdir+os.sep+'testB'+os.sep+'anno'\n",
    "\n",
    "\n",
    "if not os.path.isdir(raw_img_train_location):\n",
    "    os.makedirs(raw_img_train_location)\n",
    "if not os.path.isdir(raw_img_testA_location):\n",
    "    os.makedirs(raw_img_testA_location)\n",
    "if not os.path.isdir(raw_img_testB_location):\n",
    "    os.makedirs(raw_img_testB_location)\n",
    "\n",
    "if not os.path.isdir(anno_img_train_location):\n",
    "    os.makedirs(anno_img_train_location)\n",
    "if not os.path.isdir(anno_img_testA_location):\n",
    "    os.makedirs(anno_img_testA_location)\n",
    "if not os.path.isdir(anno_img_testB_location):\n",
    "    os.makedirs(anno_img_testB_location)\n",
    "\n",
    "def copy_img(path,list):\n",
    "    for i in range(len(list)):\n",
    "        new_obj_name = list[i]\n",
    "        shutil.copy(mydir+'\\\\'+new_obj_name,path+'\\\\'+new_obj_name)\n",
    "\n",
    "copy_img(raw_img_train_location,trainset)\n",
    "copy_img(raw_img_testA_location,testsetA) \n",
    "copy_img(raw_img_testB_location,testsetB)\n",
    "copy_img(anno_img_train_location,trainmask)\n",
    "copy_img(anno_img_testA_location,testmaskA)\n",
    "copy_img(anno_img_testB_location,testmaskB)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataset to make raw images and its masks are corresponding.\n",
    "\n",
    "def namesort(path,way):\n",
    "    # 0 for raw, 1 for anno\n",
    "    labelList = []  # 类标签列表\n",
    "    datasetList = listdir(path)\n",
    "    datasetload = []\n",
    "    if way==0:\n",
    "        list.sort(datasetList,key=lambda x: int(x[6:-4]))\n",
    "    else:\n",
    "        list.sort(datasetList,key=lambda x: int(x[6:-9]))\n",
    "    for i in range(len(datasetList)):\n",
    "        temp=imread(path+\"\\\\\"+datasetList[i])\n",
    "        datasetload.append(temp)\n",
    "    return datasetList,datasetload\n",
    "\n",
    "(testsetA,testsetAraw) = namesort(\"testA/raw\",0)\n",
    "(testmaskA,testmaskAanno) = namesort(\"testA/anno\",1)\n",
    "(testsetB,testsetBraw) = namesort(\"testB/raw\",0)\n",
    "(testmaskB,testmaskBanno) = namesort(\"testB/anno\",1)\n",
    "(trainset,trainsetraw) = namesort(\"train/raw\",0)\n",
    "(trainmask,trainmaskanno) = namesort(\"train/anno\",1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop images to get larger dataset.\n",
    "\n",
    "newdir = os.getcwd()\n",
    "\n",
    "raw_img_train_cropped_location = newdir+os.sep+'train'+os.sep+'cropped'+os.sep+'raw'\n",
    "raw_img_testA_cropped_location = newdir+os.sep+'testA'+os.sep+'cropped'+os.sep+'raw'\n",
    "raw_img_testB_cropped_location = newdir+os.sep+'testB'+os.sep+'cropped'+os.sep+'raw'\n",
    "anno_img_train_cropped_location = newdir+os.sep+'train'+os.sep+'cropped'+os.sep+'anno'\n",
    "anno_img_testA_cropped_location = newdir+os.sep+'testA'+os.sep+'cropped'+os.sep+'anno'\n",
    "anno_img_testB_cropped_location = newdir+os.sep+'testB'+os.sep+'cropped'+os.sep+'anno'\n",
    "\n",
    "\n",
    "if not os.path.isdir(raw_img_train_cropped_location):\n",
    "    os.makedirs(raw_img_train_cropped_location)\n",
    "if not os.path.isdir(raw_img_testA_cropped_location):\n",
    "    os.makedirs(raw_img_testA_cropped_location)\n",
    "if not os.path.isdir(raw_img_testB_cropped_location):\n",
    "    os.makedirs(raw_img_testB_cropped_location)\n",
    "\n",
    "if not os.path.isdir(anno_img_train_cropped_location):\n",
    "    os.makedirs(anno_img_train_cropped_location)\n",
    "if not os.path.isdir(anno_img_testA_cropped_location):\n",
    "    os.makedirs(anno_img_testA_cropped_location)\n",
    "if not os.path.isdir(anno_img_testB_cropped_location):\n",
    "    os.makedirs(anno_img_testB_cropped_location)\n",
    "\n",
    "\n",
    "\n",
    "def crop_img(raw_picture,anno_picture,crop_size,path1,path2):\n",
    "    count =0\n",
    "    ##raw_picture：raw images, anno_picture:anno images，path1:raw path，path2:anno path\n",
    "    for i in range(len(raw_picture)):\n",
    "        for j in range(2):\n",
    "            raw_img = raw_picture[i]\n",
    "            anno_img = anno_picture[i]\n",
    "            x_shape = raw_img.shape[0]-crop_size\n",
    "            y_shape = raw_img.shape[1]-crop_size\n",
    "            x1 = random.randint(0,int(x_shape/2))\n",
    "            x2 = random.randint(int(x_shape/2),x_shape)\n",
    "            y1 = random.randint(0,int(y_shape/2))\n",
    "            y2 = random.randint(int(y_shape/2),y_shape)\n",
    "            if j == 0:\n",
    "                cropped_raw_img = raw_img[x1:x1+crop_size,:]\n",
    "                cropped_raw_img = cropped_raw_img[:,y1:y1+crop_size]\n",
    "                cropped_anno_img = anno_img[x1:x1+crop_size,:]\n",
    "                cropped_anno_img = cropped_anno_img[:,y1:y1+crop_size]\n",
    "            else:\n",
    "                cropped_raw_img = raw_img[x2:x2+crop_size,:]\n",
    "                cropped_raw_img = cropped_raw_img[:,y2:y2+crop_size]\n",
    "                cropped_anno_img = anno_img[x2:x2+crop_size,:]\n",
    "                cropped_anno_img = cropped_anno_img[:,y2:y2+crop_size]\n",
    "            if cropped_anno_img.shape[0]!=400 or cropped_anno_img.shape[1]!=400:\n",
    "                print('error')\n",
    "            count = count+1\n",
    "            Image.fromarray(cropped_raw_img).save(path1+os.sep+str(count)+'.png')\n",
    "            Image.fromarray(cropped_anno_img).save(path2+os.sep+str(count)+'.png')\n",
    "    \n",
    "    list1 = os.listdir(path1)\n",
    "    list2 = os.listdir(path2)\n",
    "    \n",
    "    return list1,list2 \n",
    "\n",
    "[testsetA,testmaskA]=crop_img(testsetAraw,testmaskAanno,400,raw_img_testA_cropped_location,anno_img_testA_cropped_location)\n",
    "[testsetB,testmaskB]=crop_img(testsetBraw,testmaskBanno,400,raw_img_testB_cropped_location,anno_img_testB_cropped_location)\n",
    "[trainset,trainmask]=crop_img(trainsetraw,trainmaskanno,400,raw_img_train_cropped_location,anno_img_train_cropped_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE AUGMENTATION \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def batch_generator(img_list, anno_list, batch_size, num_of_classes=2,transfrom=transform):\n",
    "    images=[]\n",
    "    annos=[]\n",
    "    for i in range(batch_size):\n",
    "#         rand_int = random.randint(0, len(img_list)-1)\n",
    "        rand_int = int(np.random.choice(len(img_list)-1,size=1,replace=False))\n",
    "#         data=range(len(img_list))\n",
    "#         rand_int=data.sample(n=1, replace=False)\n",
    "        img = np.array(Image.open(img_list[rand_int]))\n",
    "        img=transform(img)\n",
    "        img=np.array(img)\n",
    "        images.append(img)\n",
    "        anno = np.array(Image.open(anno_list[rand_int]).convert(\"L\"))\n",
    "        anno[anno>0] = 1\n",
    "        anno_reshaped = np.zeros((anno.shape[0], anno.shape[1], num_of_classes))\n",
    "    \n",
    "        for i in range(num_of_classes):\n",
    "\n",
    "            anno_reshaped[:, :, i][anno == i] = 1\n",
    "        \n",
    "        annos.append(anno_reshaped)\n",
    "        \n",
    "    images=np.array(images)\n",
    "    annos=np.array(annos)\n",
    "\n",
    "\n",
    "    return images, annos\n",
    "    \n",
    "    \n",
    "\n",
    "path_to_images = 'C:\\\\Users\\\\炸酱面\\\\Downloads\\\\project\\\\train\\\\cropped\\\\raw'\n",
    "path_to_annotations = 'C:\\\\Users\\\\炸酱面\\\\Downloads\\\\project\\\\train\\\\cropped\\\\anno'\n",
    "img_list = sorted(trainset)\n",
    "anno_list = sorted(trainmask)\n",
    "img_list = glob.glob(path_to_images+os.sep+\"*.png\")\n",
    "anno_list = glob.glob(path_to_annotations+os.sep+\"*.png\")\n",
    "\n",
    "\n",
    "batch_size=5\n",
    "\n",
    "images, annos = batch_generator(img_list, anno_list,batch_size, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 400, 400])\n",
      "torch.Size([5, 2, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "#check batch and show some data\n",
    "\n",
    "images = torch.from_numpy(images)\n",
    "annos = torch.from_numpy(annos)\n",
    "annos = annos.permute(0,3,1,2)\n",
    "print(images.shape)\n",
    "print(annos.shape)\n",
    "\n",
    "\n",
    "# plt.imshow(images[1,:,:,:])\n",
    "# plt.imshow()\n",
    "# plt.imshow(images[1,:,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.pool0 = nn.MaxPool2d(3, 2, padding=1)  # 256 -> 128\n",
    "        self.enc_conv1 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(3, 2, padding=1)  # 128 -> 64\n",
    "        self.enc_conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(3, 2, padding=1)  # 64 -> 32\n",
    "        self.enc_conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(3, 2, padding=1)  # 32 -> 16\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = nn.Conv2d(64, 64, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.Upsample(32)  # 16 -> 32\n",
    "        self.dec_conv0 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.upsample1 = nn.Upsample(64)  # 32 -> 64\n",
    "        self.dec_conv1 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.upsample2 = nn.Upsample(128)  # 64 -> 128\n",
    "        self.dec_conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.upsample3 = nn.Upsample(400)  # 128 -> 256\n",
    "        self.dec_conv3 = nn.Conv2d(64, 2, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e0 = self.pool0(F.relu(self.enc_conv0(x)))\n",
    "        e1 = self.pool1(F.relu(self.enc_conv1(e0)))\n",
    "        e2 = self.pool2(F.relu(self.enc_conv2(e1)))\n",
    "        e3 = self.pool3(F.relu(self.enc_conv3(e2)))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.relu(self.bottleneck_conv(e3))\n",
    "\n",
    "        # decoder\n",
    "        d0 = F.relu(self.dec_conv0(self.upsample0(b)))\n",
    "        d1 = F.relu(self.dec_conv1(self.upsample1(d0)))\n",
    "        d2 = F.relu(self.dec_conv2(self.upsample2(d1)))\n",
    "        d3 = self.dec_conv3(self.upsample3(d2))  # no activation\n",
    "        d3 = torch.sigmoid(d3)\n",
    "        return d3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegNet(\n",
      "  (enc_conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (enc_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (enc_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (enc_conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (bottleneck_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upsample0): Upsample(size=32, mode=nearest)\n",
      "  (dec_conv0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upsample1): Upsample(size=64, mode=nearest)\n",
      "  (dec_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upsample2): Upsample(size=128, mode=nearest)\n",
      "  (dec_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upsample3): Upsample(size=400, mode=nearest)\n",
      "  (dec_conv3): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=SegNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001,momentum=0.9,weight_decay=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 2 \n",
    "steps=34\n",
    "\n",
    "# steps = 3 \n",
    "for epoch in range(num_epoch):  \n",
    "    running_loss = 0.0\n",
    "    avg_loss=0.0\n",
    "    print('* Epoch %d/%d' % (epoch+1, num_epoch))\n",
    "    net.train()\n",
    "    for step in range(steps):\n",
    "       \n",
    "        images, annos = batch_generator(img_list, anno_list,batch_size, 2)\n",
    "        images = torch.from_numpy(images)\n",
    "        annos = torch.from_numpy(annos)\n",
    "        annos = annos.float()\n",
    "        annos = annos.permute(0,3,1,2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "      \n",
    "        outputs = net(images)\n",
    "       # print(outputs)\n",
    "     #   plt.imshow(outputs.detach().numpy())\n",
    "        loss = criterion(outputs, annos)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "#        running_loss += loss.data \n",
    "        \n",
    "#         if step < 57:    # print every 1000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, step + 1, running_loss / batch_size))\n",
    "#         running_loss = 0.0\n",
    "    avg_loss += loss / steps\n",
    "    print(' -- loss: %f' % avg_loss)       \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    imshow=images.permute(0,2,3,1)\n",
    "    outshow=outputs.permute(0,2,3,1)\n",
    "    for k in range(3):\n",
    "        plt.subplot(3, 3, k+1)\n",
    "        plt.imshow(imshow[k,:,:,:])\n",
    "        plt.title('Real')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(3, 3, k+4)\n",
    "        plt.imshow(outshow[k,:,:,0].detach().numpy(), cmap='gray')\n",
    "        plt.title('Output1')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3,3,k+7)\n",
    "        plt.imshow(outshow[k,:,:,1].detach().numpy(), cmap='gray')\n",
    "        plt.title('Output2')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('%d / %d - loss: %f' % (epoch+1, num_epoch, avg_loss))\n",
    "    plt.show()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
