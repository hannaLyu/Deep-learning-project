{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "from os import listdir\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdir = os.getcwd()\n",
    "mydir = newdir+os.sep+'Warwick QU Dataset (Released 2016_07_08)'\n",
    "pathDir =  os.listdir(mydir)   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate dataset to 3 class : testA, test B, train and its masks.\n",
    "testsetA = []\n",
    "testsetB = []\n",
    "trainset = []\n",
    "testmaskA = []\n",
    "testmaskB = []\n",
    "trainmask = []\n",
    "\n",
    "for allDir in pathDir:      \n",
    "    if allDir.startswith('testA')==True and allDir.endswith('anno.bmp')==True:     \n",
    "\n",
    "        testmaskA.append(allDir)\n",
    "        \n",
    "    if allDir.startswith('testA')==True and allDir.endswith('anno.bmp')==False:\n",
    "  \n",
    "        testsetA.append(allDir)\n",
    "\n",
    "    if allDir.startswith('testB')==True and allDir.endswith('anno.bmp')==True:\n",
    "       \n",
    "        testmaskB.append(allDir)\n",
    "\n",
    "    if allDir.startswith('testB')==True and allDir.endswith('anno.bmp')==False:\n",
    "\n",
    "        testsetB.append(allDir)\n",
    "\n",
    "    if allDir.startswith('train')==True and allDir.endswith('anno.bmp')==True:\n",
    "        \n",
    "        trainmask.append(allDir)\n",
    "\n",
    "    if allDir.startswith('train')==True and allDir.endswith('anno.bmp')==False:\n",
    "        \n",
    "        trainset.append(allDir)\n",
    "\n",
    "#Build new dataset root  \n",
    "newdir = os.getcwd()\n",
    "raw_img_train_location = newdir+os.sep+'train'+os.sep+'raw'\n",
    "raw_img_testA_location = newdir+os.sep+'testA'+os.sep+'raw'\n",
    "raw_img_testB_location = newdir+os.sep+'testB'+os.sep+'raw'\n",
    "anno_img_train_location = newdir+os.sep+'train'+os.sep+'anno'\n",
    "anno_img_testA_location = newdir+os.sep+'testA'+os.sep+'anno'\n",
    "anno_img_testB_location = newdir+os.sep+'testB'+os.sep+'anno'\n",
    "\n",
    "\n",
    "if not os.path.isdir(raw_img_train_location):\n",
    "    os.makedirs(raw_img_train_location)\n",
    "if not os.path.isdir(raw_img_testA_location):\n",
    "    os.makedirs(raw_img_testA_location)\n",
    "if not os.path.isdir(raw_img_testB_location):\n",
    "    os.makedirs(raw_img_testB_location)\n",
    "\n",
    "if not os.path.isdir(anno_img_train_location):\n",
    "    os.makedirs(anno_img_train_location)\n",
    "if not os.path.isdir(anno_img_testA_location):\n",
    "    os.makedirs(anno_img_testA_location)\n",
    "if not os.path.isdir(anno_img_testB_location):\n",
    "    os.makedirs(anno_img_testB_location)\n",
    "\n",
    "def copy_img(path,list):\n",
    "    for i in range(len(list)):\n",
    "        new_obj_name = list[i]\n",
    "        shutil.copy(mydir+'\\\\'+new_obj_name,path+'\\\\'+new_obj_name)\n",
    "\n",
    "copy_img(raw_img_train_location,trainset)\n",
    "copy_img(raw_img_testA_location,testsetA) \n",
    "copy_img(raw_img_testB_location,testsetB)\n",
    "copy_img(anno_img_train_location,trainmask)\n",
    "copy_img(anno_img_testA_location,testmaskA)\n",
    "copy_img(anno_img_testB_location,testmaskB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the dataset to make raw images and its masks are corresponding.\n",
    "\n",
    "def namesort(path,way):\n",
    "    # 0 for raw, 1 for anno\n",
    "    labelList = []  \n",
    "    datasetList = listdir(path)\n",
    "    datasetload = []\n",
    "    if way==0:\n",
    "        list.sort(datasetList,key=lambda x: int(x[6:-4]))\n",
    "    else:\n",
    "        list.sort(datasetList,key=lambda x: int(x[6:-9]))\n",
    "    for i in range(len(datasetList)):\n",
    "        temp=imread(path+\"\\\\\"+datasetList[i])\n",
    "        datasetload.append(temp)\n",
    "    return datasetList,datasetload\n",
    "\n",
    "(testsetA,testsetAraw) = namesort(\"testA/raw\",0)\n",
    "(testmaskA,testmaskAanno) = namesort(\"testA/anno\",1)\n",
    "(testsetB,testsetBraw) = namesort(\"testB/raw\",0)\n",
    "(testmaskB,testmaskBanno) = namesort(\"testB/anno\",1)\n",
    "(trainset,trainsetraw) = namesort(\"train/raw\",0)\n",
    "(trainmask,trainmaskanno) = namesort(\"train/anno\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "size = (400,400)\n",
    "#  train_image = [resize(x,size,mode='constant',anti_aliasing=True) for x in trainsetraw]\n",
    "#  train_anno = [resize(y,size,mode='constant',anti_aliasing=False) for y in trainmaskanno]\n",
    "testA_image = [resize(x,size,mode='constant',anti_aliasing=True) for x in testsetAraw]\n",
    "testA_anno = [resize(y,size,mode='constant',anti_aliasing=False) for y in testmaskAanno]\n",
    "testB_image = [resize(z,size,mode='constant',anti_aliasing=True) for z in testsetBraw]\n",
    "testB_anno = [resize(p,size,mode='constant',anti_aliasing=False) > 0.5 for p in testmaskBanno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(raw_picture,anno_picture,crop_size):\n",
    "    ##raw_picture：raw images, anno_picture:anno images，path1:raw path，path2:anno path\n",
    "    cropped_raw_result = []\n",
    "    cropped_anno_result = []\n",
    "#      for i in range(len(raw_picture)):\n",
    "    for j in range(2):\n",
    "        raw_img = raw_picture\n",
    "        anno_img = anno_picture\n",
    "        x_shape = raw_img.shape[0]-crop_size\n",
    "        y_shape = raw_img.shape[1]-crop_size\n",
    "        x1 = random.randint(0,int(x_shape/2))\n",
    "        x2 = random.randint(int(x_shape/2),x_shape)\n",
    "        y1 = random.randint(0,int(y_shape/2))\n",
    "        y2 = random.randint(int(y_shape/2),y_shape)\n",
    "        if j == 0:\n",
    "            cropped_raw_img = raw_img[x1:x1+crop_size,:]\n",
    "            cropped_raw_img = cropped_raw_img[:,y1:y1+crop_size]\n",
    "            cropped_anno_img = anno_img[x1:x1+crop_size,:]\n",
    "            cropped_anno_img = cropped_anno_img[:,y1:y1+crop_size]\n",
    "        else:\n",
    "            cropped_raw_img = raw_img[x2:x2+crop_size,:]\n",
    "            cropped_raw_img = cropped_raw_img[:,y2:y2+crop_size]\n",
    "            cropped_anno_img = anno_img[x2:x2+crop_size,:]\n",
    "            cropped_anno_img = cropped_anno_img[:,y2:y2+crop_size]\n",
    "        if cropped_anno_img.shape[0]!=400 or cropped_anno_img.shape[1]!=400:\n",
    "            print('error')\n",
    "        cropped_raw_result.append(cropped_raw_img)\n",
    "        cropped_anno_result.append(cropped_anno_img)\n",
    " \n",
    "    \n",
    "    return cropped_raw_result,cropped_anno_result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Data AUGMENTATION \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "path_to_images = newdir+os.sep+'train\\\\raw'\n",
    "path_to_annotations = newdir+os.sep+'train\\\\anno'\n",
    "\n",
    "\n",
    "def batch_generator(img_list, anno_list, batch_size, num_of_classes=2,transform=transform):\n",
    "    images=[]\n",
    " #   annos_temp=[]\n",
    "    annos=[]\n",
    "    rand_int = int(np.random.choice(len(img_list)-1,size=1,replace=False))\n",
    "    img =  np.array(Image.open(path_to_images+os.sep+img_list[rand_int]))\n",
    "    anno = np.array(Image.open(path_to_annotations+os.sep+anno_list[rand_int]).convert(\"L\"))\n",
    "#     print(anno.shape)\n",
    "    anno[anno>0] = 1\n",
    "#     print(anno)\n",
    "#     print(img.shape)\n",
    "#     anno_reshaped = np.zeros((anno.shape[0], anno.shape[1], num_of_classes))\n",
    "#     print(anno.shape[0])\n",
    "#     print(anno.shape[1])\n",
    "#     for i in range(num_of_classes):\n",
    "#         anno_reshaped[:, :, i][anno == i] = 1\n",
    "#     annos_temp.append(anno_reshaped)\n",
    "#     annos_temp=np.array(annos_temp)\n",
    "#     annos_temp=annos_temp.astype(np.uint8)\n",
    "#     print(annos_temp.shape)\n",
    "#     annos_temp.resize([annos_temp.shape[1],annos_temp.shape[2],annos_temp.shape[3]])\n",
    "    #print(annos.dtype)\n",
    "#data augmentation\n",
    "    for i in range(batch_size):\n",
    "        image,anno_crop=crop_img(img,anno,400)\n",
    "       # print(anno_crop[0].shape)\n",
    "        image1=transform(image[0])\n",
    "        image2=transform(image[1])\n",
    "       \n",
    "        anno1 =transform(anno_crop[0])\n",
    "        anno2 =transform(anno_crop[1])\n",
    "        #print(anno2.shape)\n",
    "        random_angle = np.random.randint(1, 360)\n",
    "        image1_rotate=TF.rotate(image1,random_angle)\n",
    "        image2_rotate=TF.rotate(image2,random_angle)\n",
    "        anno1_rotate=TF.rotate(anno1,random_angle)\n",
    "        anno2_rotate=TF.rotate(anno2,random_angle)\n",
    "        image1_rotate=np.array(image1_rotate)\n",
    "        image2_rotate=np.array(image2_rotate)\n",
    "        anno1_rotate=np.array(anno1_rotate)\n",
    "        anno2_rotate=np.array(anno2_rotate)\n",
    "       # print(anno2_rotate.shape)\n",
    "        images.append(image1_rotate)\n",
    "        images.append(image2_rotate)\n",
    "        annos.append(anno1_rotate)\n",
    "        annos.append(anno2_rotate)\n",
    "        images_train=np.array(annos)\n",
    "        annos_train=np.array(train_annos)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    annos_result.shape=annos_result.shape+(1,)\n",
    "       \n",
    "     #   anno=np.array(anno)\n",
    "        \n",
    "\n",
    "#             anno[anno>0] = 1\n",
    "#             print(anno.shape)\n",
    "#             anno_reshaped = np.zeros((anno.shape[0], anno.shape[1], num_of_classes))\n",
    "\n",
    "#             for i in range(num_of_classes):\n",
    "\n",
    "#                 anno_reshaped[:, :, i][anno == i] = 1\n",
    "  \n",
    "#             annos.append(anno_reshaped)\n",
    "#         images = np.array(images)\n",
    "    \n",
    "#         annos = np.array(annos)\n",
    "    \n",
    "    return images_result, annos_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "#get batch images\n",
    "\n",
    "path_to_images = newdir+os.sep+'train\\\\raw'\n",
    "path_to_annotations = newdir+os.sep+'train\\\\anno'\n",
    "# img_list = sorted(trainset)\n",
    "# anno_list = sorted(trainmask)\n",
    "# img_list = glob.glob(path_to_images+os.sep+\"*.bmp\")\n",
    "# anno_list = glob.glob(path_to_annotations+os.sep+\"*.bmp\")\n",
    "\n",
    "\n",
    "batch_size = 6\n",
    "train_image, train_annos = batch_generator(trainset,trainmask,batch_size,2,transform)\n",
    "print(len(train_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 400, 400, 1, 1, 1, 1, 1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (400, 400, 1, 1, 1, 1) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-2006e9d7e5fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannoshow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'annos1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     plt.axis('off')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2682\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2683\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2684\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1599\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1601\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5671\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[1;32m--> 690\u001b[1;33m                             .format(self._A.shape))\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (400, 400, 1, 1, 1, 1) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(train_annos.shape)\n",
    "\n",
    "\n",
    "\n",
    "for k in range(batch_size):\n",
    "    \n",
    "    imshow = train_image\n",
    "    annoshow = train_annos\n",
    "    plt.subplot(3, 6, k+1)\n",
    "    plt.imshow(imshow[k,:,:,:])\n",
    "    plt.title('image')\n",
    "    plt.subplot(3, 6, k+7)\n",
    "    plt.imshow(annoshow[k,:,:,0])\n",
    "    plt.title('annos1')\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(3, 6, k+13)\n",
    "#     plt.imshow(annos[k,:,:,1])\n",
    "#     plt.title('annos2')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder (downsampling)\n",
    "        self.enc_conv0 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn0=nn.BatchNorm2d(64)\n",
    "        self.pool0 = nn.MaxPool2d(3, 2, padding=1)  # 256 -> 128\n",
    "        self.enc_conv1 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(3, 2, padding=1)  # 128 -> 64\n",
    "        self.enc_conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn2=nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(3, 2, padding=1)  # 64 -> 32\n",
    "        self.enc_conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(64)\n",
    "        self.pool3 = nn.MaxPool2d(3, 2, padding=1)  # 32 -> 16\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = nn.Conv2d(64, 64, 3, padding=1)\n",
    "\n",
    "        # decoder (upsampling)\n",
    "        self.upsample0 = nn.Upsample(32)  # 16 -> 32\n",
    "        self.dec_conv0 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn_dec0=nn.BatchNorm2d(64)\n",
    "        self.upsample1 = nn.Upsample(64)  # 32 -> 64\n",
    "        self.dec_conv1 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn_dec1=nn.BatchNorm2d(64)\n",
    "        self.upsample2 = nn.Upsample(128)  # 64 -> 128\n",
    "        self.dec_conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn_dec2=nn.BatchNorm2d(64)\n",
    "        self.upsample3 = nn.Upsample(400)  # 128 -> 256\n",
    "        self.dec_conv3 = nn.Conv2d(64, 3, 3, padding=1)\n",
    "        self.bn_dec3=nn.BatchNorm2d(64)\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e0 = self.pool0(F.relu(self.bn0(self.enc_conv0(x))))\n",
    "        e1 = self.pool1(F.relu(self.bn1(self.enc_conv1(e0))))\n",
    "        e2 = self.pool2(F.relu(self.bn2(self.enc_conv2(e1))))\n",
    "        e3 = self.pool3(F.relu(self.bn3(self.enc_conv3(e2))))\n",
    "\n",
    "        # bottleneck\n",
    "        b = F.relu(self.bottleneck_conv(e3))\n",
    "\n",
    "        # decoder\n",
    "        d0 = F.relu(self.dec_conv0(self.bn_dec0(self.upsample0(b))))\n",
    "        d1 = F.relu(self.dec_conv1(self.bn_dec1(self.upsample1(d0))))\n",
    "        d2 = F.relu(self.dec_conv2(self.bn_dec2(self.upsample2(d1))))\n",
    "        d3 = self.dec_conv3(self.bn_dec3(self.upsample3(d2)) ) # no activation\n",
    "        d3 = torch.softmax(d3,dim=1)\n",
    "        return d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegNet(\n",
      "  (enc_conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (enc_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (enc_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (enc_conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (bottleneck_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upsample0): Upsample(size=32, mode=nearest)\n",
      "  (dec_conv0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_dec0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (upsample1): Upsample(size=64, mode=nearest)\n",
      "  (dec_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_dec1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (upsample2): Upsample(size=128, mode=nearest)\n",
      "  (dec_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_dec2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (upsample3): Upsample(size=400, mode=nearest)\n",
      "  (dec_conv3): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_dec3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=SegNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001783987C6C8>\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "#def bce_loss(y_real, y_pred):\n",
    "#    return torch.mean(y_pred - y_real*y_pred + torch.log(1 + torch.exp(-y_pred)))\n",
    "print(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4423680000 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c806fd83849f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mannos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-45b9c140fd0c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0md1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_conv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_dec1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0md2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_conv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_dec2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0md3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_conv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_dec3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupsample3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# no activation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0md3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0md3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4423680000 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1 \n",
    "steps=3\n",
    "avg_loss=0.0\n",
    "# steps = 3 \n",
    "for epoch in range(num_epoch):  \n",
    "    running_loss = 0.0\n",
    "  \n",
    "    print('* Epoch %d/%d' % (epoch+1, num_epoch))\n",
    "    net.train()\n",
    "    for step in range(steps):\n",
    "        train_image, train_annos = batch_generator(trainset,trainmask,batch_size,2,transform)\n",
    "        images=np.array(train_image)\n",
    "        annos=np.array(train_annos)\n",
    "        images = torch.from_numpy(images)\n",
    "        annos = torch.from_numpy(annos)\n",
    "        annos = annos.float()\n",
    "        images=images.float()\n",
    "        images=images.permute(0,3,1,2)\n",
    "        annos = annos.permute(0,3,1,2)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "      \n",
    "    \n",
    "        loss = criterion(outputs, annos)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss = loss \n",
    "\n",
    "        if step < 34:   \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, step + 1, running_loss))\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        avg_loss += loss\n",
    "    avg_loss =avg_loss/steps\n",
    "    print(' -- loss: %f' % avg_loss)       \n",
    "\n",
    "    \n",
    "\n",
    "    Y_hat = net(images).detach().cpu()\n",
    "    clear_output(wait=True)\n",
    "    imshow=annos.permute(0,2,3,1)\n",
    "    outshow=Y_hat.permute(0,2,3,1)\n",
    "    \n",
    "    for k in range(3):\n",
    "        plt.subplot(3, 3, k+1)\n",
    "        plt.imshow(imshow[k,:,:,0])\n",
    "        plt.title('Real')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(3, 3, k+4)\n",
    "        plt.imshow(outshow[k,:,:,0].detach().numpy(), cmap='gray')\n",
    "        plt.title('Output1')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3,3,k+7)\n",
    "        plt.imshow(outshow[k,:,:,1].detach().numpy(), cmap='gray')\n",
    "        plt.title('Output2')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle('%d / %d - loss: %f' % (epoch+1, num_epoch, avg_loss))\n",
    "    plt.show()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
